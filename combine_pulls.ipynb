{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d708446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.ticker as mtick\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c7a513-8709-418f-840f-9be12236abe8",
   "metadata": {},
   "source": [
    "# Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29bbed0d-d209-4ec9-b0a4-e4b3b7fb51df",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Pull name\n",
    "filter_ideo = \"Y\"\n",
    "name = \"s2_mar23_aug23_ideoY\"\n",
    "t1_follower_set = \"s2_mar23_ideoY\"\n",
    "t2_follower_set = \"s2_june34_ideoY\"\n",
    "\n",
    "# Initial pull of spreader friends and followers\n",
    "fr1_fn = \"_MINIMAL_FRIENDS_03.18.2023__08.28.43__START0_END-1_merged.csv\"\n",
    "fol1_fn = \"__MINIMAL_FOLLOWERS_03.18.2023__08.28.43__START0_END-1_merged.csv\"\n",
    "fol2_fn = \"merged_t3_follower_pull.csv\"\n",
    "\n",
    "    \n",
    "# Hydrated files contain user level metainfo\n",
    "\n",
    "## Spreader hydrated files \n",
    "main_hydrated1_fn = \"HydratedMain_ND22___03.28.2023__14.25.56__START0_END-1_merged.csv\"\n",
    "main_hydrated2_fn = \"HydratedMain_ND22_t1_t3_v2___10.02.2023__22.42.29__START0_END-1_merged .csv\"\n",
    "\n",
    "## Follower hydrated files \n",
    "follower_hydrated1_fn = \"HydratedFollowers_ND22___03.28.2023__13.01.40__START0_END-1_merged.csv\"\n",
    "follower_hydrated2_fn = \"HydratedFollowers_ND22_t1_t3_v2___10.02.2023__14.23.39__START0_END-1_merged.csv\"\n",
    "\n",
    "# Anchor - date relative to calculate tweet recency to (date when t1 hydrated data pulled)\n",
    "anchor = \"Oct 2 2023\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e7c5d7-028b-4ef5-b288-82e4162d3e72",
   "metadata": {},
   "source": [
    "# Get Ideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49c5e5dc-c477-44f3-9369-38798d8b8285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **********\n",
      "STARTING PULLING DATA FOR s2_mar23_aug23_ideoY\n",
      "**********\n",
      "\n",
      "\n",
      "\n",
      "processed/s2_mar23_ideoY_fol1_ideo.csv\n",
      "s2_june34_ideoY\n",
      "True\n",
      "The file 'processed/s2_mar23_ideoY_fol1_ideo.csv' already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"\\n\", \"*\"*10)\n",
    "print(\"STARTING PULLING DATA FOR {}\".format(name))\n",
    "print(\"*\"*10)\n",
    "print(\"\\n\"*2)\n",
    "\n",
    "ideo_fn = f\"processed/{t1_follower_set}_fol1_ideo.csv\"\n",
    "print(\"Ideo fn\", ideo_fn)\n",
    "print(\"t2 follower set\", t2_follower_set)\n",
    "print(os.path.exists(ideo_fn))\n",
    "if filter_ideo == \"Y\":\n",
    "    join_type = \"inner\"\n",
    "elif filter_ideo == \"N\":\n",
    "    join_type = \"left\"\n",
    "    \n",
    "if not os.path.exists(ideo_fn):\n",
    "    print(f\"Getting data for {t1_follower_set}\")\n",
    "    !python3 get_twitter_ideos.py -i $fol1_fn -id_col 'followers_id' --o $ideo_fn --j $join_type\n",
    "else:\n",
    "    print(f\"The file '{ideo_fn}' already exists.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973ec2b8",
   "metadata": {},
   "source": [
    "# Make T1 df: Columns = [main, follower, recip, theta]\n",
    "\n",
    "1. FollowerIdeology = FollowerIdeology JOIN Followers\n",
    "2. FollowerIdeology = FollowerIdeology LEFT JOIN Friends (get reciprocal flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c9be36c-9476-49ed-b844-123a9c9a9232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making T1 df\n",
      "After making T1 df, there are 944972 followers and 5593 spreaders\n"
     ]
    }
   ],
   "source": [
    "print(\"Making T1 df\")\n",
    "fr_1 = pd.read_csv(fr1_fn, dtype={'main':'object', 'friends_id':'object'})\n",
    "fr_1['recip'] = 1\n",
    "fol_1 = pd.read_csv(fol1_fn, dtype={'main':'object', 'followers_id':'object'})\n",
    "\n",
    "fol_1_ideo = pd.read_csv(ideo_fn, dtype={'main':'object', 'followers_id':'object'})[['followers_id', 'theta']]\n",
    "fol_1_ideo = pd.merge(fol_1, fol_1_ideo, left_on='followers_id', right_on='followers_id')\n",
    "fol_1_ideo = fol_1_ideo.drop_duplicates(subset=['followers_id', 'main'])\n",
    "fol_1_ideo = pd.merge(fol_1_ideo, fr_1, left_on=['main', 'followers_id'], right_on=['main', 'friends_id'], how='left')\n",
    "fol_1_ideo['recip'] = fol_1_ideo['recip'].apply(lambda x: 1 if x==1.0 else 0)\n",
    "fol_1_ideo = fol_1_ideo[['main', 'followers_id', 'recip', 'theta']]\n",
    "if fr1_fn == \"-1\":\n",
    "    fol_1_ideo['recip'] = np.NaN\n",
    "print(f\"After making T1 df, there are {len(fol_1_ideo['followers_id'].unique())} followers and {len(fol_1_ideo['main'].unique())} spreaders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd45b9b-cdbb-406d-86a7-ff8a19f6af3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Find banned spreaders and followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80973f-dc5d-44f9-b9bf-766f9b34dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ban_fn = f\"{name}_banned.csv\"\n",
    "\n",
    "print(\"Getting banned users\")\n",
    "\n",
    "####################\n",
    "# BANNED SPREADERS\n",
    "####################\n",
    "banned_spreaders = []\n",
    "# First we look in follower pulls for anytime I logged an error with the spreaders\n",
    "for fn in [fol1_fn, fol2_fn]:\n",
    "    tdf = pd.read_csv(fn, dtype={'main':'object', 'followers_id':'object'})\n",
    "    tdf['er'] = tdf['followers_id'].apply(lambda x: 1 if x.startswith('-99') else 0)\n",
    "    tdf_er = tdf.query(\"er==1\")['main'].tolist()\n",
    "    banned_spreaders.extend(tdf_er)\n",
    "\n",
    "# Now we will look at anytime it was not possible to pull follower counts in hydrated data\n",
    "for fn in [main_hydrated1_fn, main_hydrated2_fn]:\n",
    "    if fn != \"-1\":\n",
    "        tdf = pd.read_csv(fn, dtype={'user_id':'object'})\n",
    "        banned_spreaders.extend(tdf.query(\"follower_count<0\")['user_id'].tolist())\n",
    "        banned_spreaders.extend(tdf.query(\"tweet_count<0\")['user_id'].tolist())\n",
    "\n",
    "\n",
    "####################\n",
    "# BANNED FOLLOWERS\n",
    "####################\n",
    "# For followers, too, we will look at anytime it was not possible to pull follower count\n",
    "banned_followers = []\n",
    "for fn in [follower_hydrated1_fn, follower_hydrated2_fn]:\n",
    "    if fn != \"-1\":\n",
    "        tdf = pd.read_csv(fn, dtype={'user_id':'object'})\n",
    "        banned_followers.extend(tdf.query(\"follower_count<0\")['user_id'].tolist())\n",
    "        banned_followers.extend(tdf.query(\"tweet_count<0\")['user_id'].tolist())\n",
    "\n",
    "banned_followers, banned_spreaders = set(banned_followers), set(banned_spreaders)\n",
    "print(f\"Before removing banned, there are {len(fol_1_ideo['followers_id'].unique())} followers and {len(fol_1_ideo['main'].unique())} spreaders\")\n",
    "print(f\"There are {len(banned_followers)} removed followers and {len(banned_spreaders)} removed spreaders\")\n",
    "\n",
    "unique_spreaders = set(fol_1_ideo['main'].unique())\n",
    "intersection_spreaders = unique_spreaders.intersection(banned_spreaders)\n",
    "print(f\"Out of {len(banned_spreaders)} banned spreaders, {len(intersection_spreaders)} are present in the fol_1_ideo DataFrame.\")\n",
    "\n",
    "####################\n",
    "# WRITE TO DF\n",
    "####################\n",
    "ban_data = []\n",
    "for banned_follower in banned_followers:\n",
    "    ban_data.append({'user_id':banned_follower, 'type':'follower'})\n",
    "for banned_spreader in banned_spreaders:\n",
    "    ban_data.append({'user_id':banned_spreader, 'type':'spreader'})\n",
    "ban_df = pd.DataFrame(ban_data)\n",
    "ban_df.to_csv(\"processed/\" + ban_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4108fafd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Remove any banned spreaders and followers if there are any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2fe526",
   "metadata": {},
   "outputs": [],
   "source": [
    "fol_1_ideo = fol_1_ideo[~(fol_1_ideo['main'].isin(banned_spreaders) | fol_1_ideo['followers_id'].isin(banned_followers))]\n",
    "print(f\"After removing banned, there are {len(fol_1_ideo['followers_id'].unique())} followers and {len(fol_1_ideo['main'].unique())} spreaders\")\n",
    "fol_1_ideo.to_csv(f\"processed/{name}_fol_1_ideo_remove_ban.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1d5ae5-f603-46de-a8c7-8e7e185ca59a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Add activity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a75d4e-5edb-48ed-981f-62af1a3b1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "def calculate_days_since_tweet(date, reference_date):\n",
    "    days = (reference_date - date).dt.days\n",
    "    # Replace negative values with 0. This happens if:\n",
    "    # - pull begins on Jan 1\n",
    "    # - gets to user on Jan 5nd\n",
    "    # - user's last tweet was Jan 3\n",
    "    # We will get -2 \n",
    "    days = days.clip(0)  \n",
    "    return days\n",
    "\n",
    "def process_dataframe(df, anchor=anchor):\n",
    "    reference_date = datetime.strptime(anchor, '%b %d %Y').replace(tzinfo=pytz.UTC)\n",
    "    df['last_tweet_date'] = pd.to_datetime(df['last_tweet_date'], errors='coerce', format='%a %b %d %H:%M:%S %z %Y')\n",
    "    df = df.dropna(subset=['last_tweet_date'])\n",
    "    df['days_since_tweet'] = calculate_days_since_tweet(df['last_tweet_date'], reference_date)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Set up data\n",
    "#########################\n",
    "make_percent = lambda num, denom: str(int((num/denom)*100)) + \"%\"\n",
    "fol_1_ideo = pd.read_csv(f\"processed/{name}_fol_1_ideo_remove_ban.csv\",  dtype={'main':'object', 'followers_id':'object'})\n",
    "followers = list(set(fol_1_ideo['followers_id'].tolist()))\n",
    "hydf2 = pd.read_csv(follower_hydrated2_fn, dtype={'user_id':'object'})\n",
    "hydf2 = hydf2.query(\"user_id in @ followers\")\n",
    "#########################\n",
    "\n",
    "\n",
    "# Pull tweet days\n",
    "#########################\n",
    "tweet_days_fn = f\"{name}_follower_tweet_recency.csv\"\n",
    "if not os.path.exists(tweet_days_fn):\n",
    "    print(\"Getting tweet days\")\n",
    "    tweet_days_df = process_dataframe(hydf2)\n",
    "    tweet_days_errors = len(hydf2) - len(tweet_days_df)\n",
    "    tweet_days_df[['user_id', 'days_since_tweet']].dropna(subset=['days_since_tweet']).to_csv(\"processed/\" + tweet_days_fn)\n",
    "    print(\"Pulled tweet days\")\n",
    "    print(f\"Couldn't pull tweet days for {tweet_days_errors} out of {len(hydf2)}, {make_percent(tweet_days_errors, len(hydf2))}\")\n",
    "else:\n",
    "    print(\"Tweet days already pulled\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83e0173",
   "metadata": {},
   "source": [
    "# Add back features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN FILES \n",
    "##############################\n",
    "# The resulting dataframe from getting ideology and removing any banned people\n",
    "fol_1_ideo = pd.read_csv(f\"processed/{name}_fol_1_ideo_remove_ban.csv\",dtype={'main':'object', 'followers_id':'object'})\n",
    "print(f\"After ideology and ban filters, we start with: {len(fol_1_ideo['followers_id'].unique())} followers and {len(fol_1_ideo['main'].unique())} spreaders\")\n",
    "\n",
    "# The activity features for followers\n",
    "tweet_days = pd.read_csv(f\"processed/{name}_follower_tweet_recency.csv\", dtype={'user_id':'object'})\n",
    "\n",
    "# Hydrated followers and spreaders containing stuff like tweet count\n",
    "hyds1 = pd.read_csv(main_hydrated1_fn, dtype={'user_id':'object'}).query(\"follower_count!='-9'\")\n",
    "hydf1 = pd.read_csv(follower_hydrated1_fn, dtype={'user_id':'object'}).query(\"follower_count!='-9'\")\n",
    "\n",
    "hyds2 = pd.read_csv(main_hydrated2_fn, dtype={'user_id':'object'}).query(\"follower_count!='-9'\")\n",
    "hydf2 = pd.read_csv(follower_hydrated2_fn, dtype={'user_id':'object'}).query(\"follower_count!='-9'\")\n",
    "\n",
    "##############################\n",
    "\n",
    "\n",
    "# ADD FEATURES\n",
    "##############################\n",
    "for c in ['follower_count', 'following_count', 'tweet_count', 'last_tweet_date', 'user_id']:\n",
    "    if c in hyds1.columns:\n",
    "        hyds1[f\"spreader_{c}\"] = hyds1[c]\n",
    "        hyds2[f\"t2_spreader_{c}\"] = hyds2[c]\n",
    "\n",
    "    if c in hydf1.columns:\n",
    "        hydf1[f\"follower_{c}\"] = hydf1[c]\n",
    "        hydf2[f\"t2_follower_{c}\"] = hydf2[c]\n",
    "\n",
    "# Merge spreader info (T1)\n",
    "fol_1_ideo = pd.merge(fol_1_ideo, hyds1[['user_id', 'spreader_tweet_count', 'spreader_following_count', 'spreader_follower_count']], left_on=['main'], right_on=['user_id'], how='inner')\n",
    "print(f\"Merge with T1 hydrated spreader info: There are {len(fol_1_ideo['followers_id'].unique())} followers and {len(fol_1_ideo['main'].unique())} spreaders\")\n",
    "\n",
    "# Merge spreader info (T2)\n",
    "fol_1_ideo = pd.merge(fol_1_ideo, hyds2[['t2_spreader_user_id', 't2_spreader_tweet_count', 't2_spreader_following_count', 't2_spreader_follower_count']], left_on=['main'], right_on=['t2_spreader_user_id'], how='inner')\n",
    "print(f\"Merge with T2 hydrated spreader info: There are {len(fol_1_ideo['followers_id'].unique())} followers and {len(fol_1_ideo['main'].unique())} spreaders\")\n",
    "\n",
    "# Merge follower info (T1)\n",
    "fol_1_ideo = pd.merge(fol_1_ideo, hydf1[['user_id', 'follower_tweet_count', 'follower_following_count', 'follower_follower_count']], left_on=['followers_id'], right_on=['user_id'], how='inner')\n",
    "print(f\"Merge with T1 hydrated follower info: There are {len(fol_1_ideo['followers_id'].unique())} followers and {len(fol_1_ideo['main'].unique())} spreaders\")\n",
    "\n",
    "# Merge follower info (T2)\n",
    "fol_1_ideo = pd.merge(fol_1_ideo, hydf2[['t2_follower_user_id', 't2_follower_tweet_count', 't2_follower_following_count', 't2_follower_follower_count']], left_on=['followers_id'], right_on=['t2_follower_user_id'], how='inner')\n",
    "print(f\"Merge with T2 hydrated follower info: There are {len(fol_1_ideo['followers_id'].unique())} followers and {len(fol_1_ideo['main'].unique())} spreaders\")\n",
    "\n",
    "\n",
    "# Remove missing again just to be 100% sure\n",
    "fol_1_ideo = fol_1_ideo.query(\"spreader_following_count != -9\")\n",
    "fol_1_ideo = fol_1_ideo.query(\"follower_following_count != -9\")\n",
    "print(f\"Remove missing people (be extra sure): There are {len(fol_1_ideo['followers_id'].unique())} followers and {len(fol_1_ideo['main'].unique())} spreaders\")\n",
    "\n",
    "# # Add back tweet recency filter\n",
    "# fol_1_ideo = pd.merge(fol_1_ideo, tweet_days, left_on=['followers_id'], right_on=['user_id'], how='inner')\n",
    "# print(f\"Merge with tweet recency data: There are {len(fol_1_ideo['followers_id'].unique())} followers and {len(fol_1_ideo['main'].unique())} spreaders\")\n",
    "\n",
    "fol_1_ideo['n_spreader_following'] = fol_1_ideo.groupby(by=['followers_id'])['followers_id'].transform('count') \n",
    "\n",
    "# Get change varaibles\n",
    "for col in ['spreader_tweet_count', 'spreader_following_count', 'spreader_follower_count', 'follower_tweet_count', 'follower_following_count', 'follower_follower_count']:\n",
    "    fol_1_ideo[f'change_{col}'] = fol_1_ideo[f't2_{col}'] - fol_1_ideo[col]\n",
    "    fol_1_ideo[f'change_{col}2'] = fol_1_ideo[f'change_{col}'].apply(lambda x: max(x, 0))\n",
    "\n",
    "    \n",
    "# add basic features\n",
    "fol_1_ideo['abs_ideo'] = fol_1_ideo['theta'].apply(lambda x: np.abs(x))\n",
    "fol_1_ideo['is_liberal'] = fol_1_ideo['theta'].apply(lambda x: 1 if x < 0 else 0)\n",
    "##############################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb374ff",
   "metadata": {},
   "source": [
    "# Find who was unfollowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd77127",
   "metadata": {},
   "outputs": [],
   "source": [
    "followed_2 = pd.read_csv(fol2_fn, dtype={'main':'object', 'followers_id':'object'})\n",
    "followed_2 = followed_2[~(followed_2['main'].isin(banned_spreaders) | followed_2['followers_id'].isin(banned_followers))]\n",
    "final_df = pd.merge(fol_1_ideo, followed_2, left_on=['main', 'followers_id'], right_on=['main', 'followers_id'], how='left', indicator=True)\n",
    "final_df = final_df.drop_duplicates(subset=['main', 'followers_id'])\n",
    "# If the follower id is only present in fol_1_ideo but not in followed_2, then we know person unfollowed\n",
    "final_df['unfollowed'] = final_df['_merge'].apply(lambda x: 1 if x == 'left_only' else 0)\n",
    "final_df['unfollowed_spreaders'] = final_df.groupby(by=['followers_id'])['unfollowed'].transform('sum')\n",
    "unf = final_df['unfollowed'].mean()\n",
    "print(f\"The unfollow_rate for {name} is {unf}\")\n",
    "final_df.to_csv(f\"processed/{name}_final_mod.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (misinformation_sim)",
   "language": "python",
   "name": "pycharm-9607488f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
